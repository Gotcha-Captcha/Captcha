{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Captcha Project - Dataset & MLflow Setup\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³ , MLflow ì„œë²„ë¥¼ ì‹¤í–‰í•˜ë©°, ngrokì„ í†µí•´ ì™¸ë¶€ ì£¼ì†Œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import time\n",
    "import socket\n",
    "\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import opening, footprint_rectangle\n",
    "\n",
    "import mlflow\n",
    "from pyngrok import ngrok\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ad5bdc",
   "metadata": {},
   "source": [
    "## 1. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ & ê²½ë¡œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kagglehubë¥¼ ì´ìš©í•´ì„œ ìµœì‹  ë²„ì „ì˜ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œ\n",
    "dataset_path = kagglehub.dataset_download(\"fournierp/captcha-version-2-images\")\n",
    "print(\"Path to dataset files:\", dataset_path)\n",
    "\n",
    "# ì´ë¯¸ì§€ê°€ ë“¤ì–´ìˆëŠ” ë””ë ‰í„°ë¦¬\n",
    "images_dir = Path(dataset_path) / \"samples\"\n",
    "image_files = list(images_dir.glob(\"*.png\")) + list(images_dir.glob(\"*.jpg\"))\n",
    "print(f\"ì°¾ì€ ì´ë¯¸ì§€ ê°œìˆ˜: {len(image_files)}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5d6349",
   "metadata": {},
   "source": [
    "## 2. MLflow & ngrok ì„¤ì • (ì„œë²„ ì‹¤í–‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì™„ì „ ì²­ì†Œ (ERR_NGROK_334 ë°©ì§€)\n",
    "try:\n",
    "    if os.name == 'posix':\n",
    "        !pkill -f ngrok\n",
    "        !pkill -f mlflow\n",
    "    ngrok.kill()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# MLflow ì„¤ì •\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"Captcha_Project_V1\")\n",
    "\n",
    "# MLflow ì„œë²„ ì‹¤í–‰ (ë°°ê²½ì‹¤í–‰ - macOS AirPlay ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ 5001 í¬íŠ¸ ì‚¬ìš©)\n",
    "# --allowed-hosts \"*\" ì˜µì…˜ì„ ì¶”ê°€í•˜ì—¬ ngrokì„ í†µí•œ ì ‘ì†ì´ ê°€ëŠ¥í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "get_ipython().system_raw(f\"{sys.executable} -m mlflow ui --port 5001 --host 0.0.0.0 --allowed-hosts '*' &\")\n",
    "\n",
    "# ì„œë²„ ë¶€íŒ… ëŒ€ê¸° (Health Check)\n",
    "print(\"MLflow ì„œë²„ ë¶€íŒ… ì¤‘...\")\n",
    "for _ in range(15):\n",
    "    time.sleep(1)\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    result = sock.connect_ex(('127.0.0.1', 5001))\n",
    "    if result == 0:\n",
    "        print(\"âœ… MLflow ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë‹µí•©ë‹ˆë‹¤!\")\n",
    "        break\n",
    "    sock.close()\n",
    "else:\n",
    "    print(\"âŒ ì„œë²„ ë¶€íŒ… ì‹œê°„ì´ ë„ˆë¬´ ê¸¸ì–´ì§‘ë‹ˆë‹¤. ë‹¤ì‹œ ì‹¤í–‰í•´ ë³´ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa4d2d2",
   "metadata": {},
   "source": [
    "## 3. ngrok í„°ë„ í™œì„±í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NGROK_AUTH_TOKEN = \"34lM1T5TWYWgnNcWPYgk7OLcLQb_4V3iPfdh1wRmCW3ykat2p\"\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "\n",
    "try:\n",
    "    # 5001ë²ˆ í¬íŠ¸ë¥¼ ì™¸ë¶€ë¡œ ê°œë°©\n",
    "    public_url = ngrok.connect(5001).public_url\n",
    "    print(f\"\\nğŸš€ ì•„ë˜ ì£¼ì†Œë¥¼ í´ë¦­í•˜ì„¸ìš”:\\n{public_url}\")\n",
    "    print(\"\\nâš ï¸  ì ‘ì† í›„ 'Visit Site' ë²„íŠ¼ì´ ë‚˜ì˜¤ë©´ í´ë¦­í•˜ì„¸ìš”.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ngrok ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ca918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 2. ìœ í‹¸ í•¨ìˆ˜ë“¤ ì •ì˜\n",
    "# ============================\n",
    "\n",
    "def extract_label_from_filename(file_path: Path) -> str:\n",
    "    \"\"\"\n",
    "    íŒŒì¼ ì´ë¦„ì—ì„œ ë ˆì´ë¸”(ì •ë‹µ í…ìŠ¤íŠ¸)ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜.\n",
    "    - ì‹¤ì œ ë°ì´í„°ì…‹ì˜ íŒŒì¼ëª… ê·œì¹™ì— ë§ê²Œ ìˆ˜ì •í•´ì•¼ í•¨.\\n\",\n",
    "    - ì˜ˆì‹œ: '2b7wD.png' -> '2b7wD'\\n\",\n",
    "    \"\"\"\n",
    "    # í™•ì¥ì ì œê±° í›„ íŒŒì¼ëª… ì „ì²´ë¥¼ ë ˆì´ë¸”ë¡œ ì‚¬ìš© (í•„ìš” ì‹œ ìŠ¬ë¼ì´ì‹±/ë¶„ë¦¬)\n",
    "    label = file_path.stem\n",
    "    return label\n",
    "\n",
    "\n",
    "def preprocess_image(img):\n",
    "    if img.ndim == 3 and img.shape[2] == 4:\n",
    "        from skimage.color import rgba2rgb\n",
    "        img = rgba2rgb(img)\n",
    "    \n",
    "    img_gray = rgb2gray(img)\n",
    "    img_resized = resize(img_gray, (50, 200))\n",
    "    \n",
    "    thresh = threshold_otsu(img_resized)\n",
    "    # ê¸€ìê°€ ë°°ê²½ë³´ë‹¤ ì–´ë‘¡ë‹¤ê³  ê°€ì • (ê²€ì • ê¸€ì”¨: False, í° ë°°ê²½: True)\n",
    "    img_bin = img_resized > thresh\n",
    "    # ë§Œì•½ ì´ë¯¸ì§€ ê°€ì¥ìë¦¬ê°€ ê²€ì€ìƒ‰ì´ë©´ ë°˜ì „ (ë°°ê²½ì„ í•­ìƒ True(í°ìƒ‰)ë¡œ ìœ ì§€)\n",
    "    if np.mean(img_bin[0, :]) < 0.5:\n",
    "        img_bin = ~img_bin\n",
    "        \n",
    "    return img_bin\n",
    "\n",
    "def preprocess_image_v2(img):\n",
    "    # ê¸°ë³¸ ì „ì²˜ë¦¬ (RGB2Gray -> Resize -> Otsu)\n",
    "    if img.ndim == 3 and img.shape[2] == 4: img = img[..., :3]\n",
    "    img_gray = rgb2gray(img)\n",
    "    img_resized = resize(img_gray, (50, 200))\n",
    "    thresh = threshold_otsu(img_resized)\n",
    "    img_bin = img_resized > thresh\n",
    "    # ë…¸ì´ì¦ˆ(ì„ ) ì œê±°: ì•„ì£¼ ì‘ì€ ì ì´ë‚˜ ì–‡ì€ ì„ ì„ ì§€ì›ë‹ˆë‹¤.\n",
    "    # 1(ë°°ê²½), 0(ê¸€ì)ì´ë¯€ë¡œ ê¸€ìë¥¼ ì§€ìš°ê¸° ìœ„í•´ ë°˜ì „ í›„ ì²˜ë¦¬\n",
    "    if np.mean(img_bin[0, :]) < 0.5: img_bin = ~img_bin\n",
    "    \n",
    "    # ë…¸ì´ì¦ˆ(ì„ ) ì œê±°\n",
    "    img_cleaned = opening(1 - img_bin, footprint_rectangle((2, 2))) \n",
    "    return 1 - img_cleaned\n",
    "\n",
    "\n",
    "def extract_hog_features(img_binary: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    HOG íŠ¹ì§• ì¶”ì¶œ\n",
    "    \"\"\"\n",
    "    features = hog(\n",
    "        img_binary,\n",
    "        orientations=9, # ê·¸ë˜ë””ì–¸íŠ¸(ê¸°ìš¸ê¸°)ì˜ ë°©í–¥ì„ ëª‡ ê°œì˜ êµ¬ê°„(Bin)ìœ¼ë¡œ ë‚˜ëˆŒ ê²ƒì¸ì§€ë¥¼ ê²°ì •\n",
    "        pixels_per_cell=(4, 4), # í•˜ë‚˜ì˜ ì…€(Cell)ì„ êµ¬ì„±í•˜ëŠ” í”½ì…€ì˜ í¬ê¸°\n",
    "        cells_per_block=(2, 2), # í•˜ë‚˜ì˜ ë¸”ë¡(Block)ì— í¬í•¨ë  ì…€ì˜ ê°œìˆ˜\n",
    "        block_norm=\"L2-Hys\", # ë¸”ë¡ ë‹¨ìœ„ ì •ê·œí™” ë°©ì‹ì„ ì„¤ì • (L2-Hys: L2-norm, clipping(Hysteresis)ì˜ ì•½ì)\n",
    "        transform_sqrt=True # ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•´ ê°ë§ˆ ë³´ì •ì— ëŒ€í•œ ìœ ë¬´\n",
    "\n",
    "    )\n",
    "    return features\n",
    "\n",
    "def segment_characters(img_bin, num_chars=5):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ë¥¼ ë‹¨ìˆœí•˜ê²Œ ë“±ë¶„í•˜ì—¬ ê¸€ìë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    h, w = img_bin.shape\n",
    "    char_width = w // num_chars\n",
    "    \n",
    "    characters = []\n",
    "    for i in range(num_chars):\n",
    "        start = i * char_width\n",
    "        end = (i + 1) * char_width\n",
    "        \n",
    "        char_img = img_bin[:, start:end]\n",
    "        char_img_resized = resize(char_img, (32, 32))\n",
    "        characters.append(char_img_resized)\n",
    "        \n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe858ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 3. ë°ì´í„° ë¡œë”© & íŠ¹ì§• ì¶”ì¶œ\n",
    "# ============================\n",
    "\n",
    "IMAGE_EXTS = [\"*.png\", \"*.jpg\", \"*.jpeg\"]\n",
    "\n",
    "image_files = []\n",
    "for ext in IMAGE_EXTS:\n",
    "    image_files.extend(list(images_dir.glob(ext)))\n",
    "\n",
    "print(f\"ì´ ì´ë¯¸ì§€ ê°œìˆ˜: {len(image_files)}\")\n",
    "\n",
    "X_char_features = []\n",
    "y_char_labels = []\n",
    "\n",
    "for path in tqdm(image_files, desc=\"íŠ¹ì§• ì¶”ì¶œ ì¤‘\"):\n",
    "    try:\n",
    "        img = imread(str(path))\n",
    "        img_bin = preprocess_image_v2(img)\n",
    "        char_images = segment_characters(img_bin, num_chars=5)\n",
    "        label_text = path.stem \n",
    "        \n",
    "        if len(char_images) == len(label_text):\n",
    "            for char_img, char_label in zip(char_images, label_text):\n",
    "                feat = extract_hog_features(char_img)\n",
    "                X_char_features.append(feat)\n",
    "                y_char_labels.append(char_label)\n",
    "                \n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "X_char_features = np.array(X_char_features)\n",
    "y_char_labels = np.array(y_char_labels)\n",
    "\n",
    "print(f\"ì´ ì¶”ì¶œëœ ê¸€ì ë°ì´í„° ìˆ˜: {len(X_char_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d85121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4. ë ˆì´ë¸” ì¸ì½”ë”© & í•™ìŠµ/ê²€ì¦ ë¶„í• \n",
    "# ============================\n",
    "\n",
    "X_char_features = np.array(X_char_features)\n",
    "y_char_labels = np.array(y_char_labels)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_char_labels)\n",
    "\n",
    "n_classes = len(label_encoder.classes_)\n",
    "print(f\"ì¸ì½”ë”©ëœ í´ë˜ìŠ¤ ê°œìˆ˜: {n_classes}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_char_features,\n",
    "    y_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "# íŠ¹ì§• ë²¡í„° ì •ê·œí™”\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"í•™ìŠµìš© ê¸€ì ìƒ˜í”Œ ìˆ˜: {X_train.shape[0]}\")\n",
    "print(f\"ê²€ì¦ìš© ê¸€ì ìƒ˜í”Œ ìˆ˜: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ec96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 5. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ (with MLflow)\n",
    "# ============================\n",
    "\n",
    "with mlflow.start_run(run_name=\"Improved_HOG_SVM_Run\"):\n",
    "    mlflow.log_param(\"max_iter\", 10000)\n",
    "    mlflow.log_param(\"model_type\", \"SVC_RBF\")\n",
    "    mlflow.log_param(\"C\", 1.0)\n",
    "    mlflow.log_param(\"hog_pixels_per_cell\", \"(4, 4)\")\n",
    "    \n",
    "    svm_model = SVC(kernel='rbf', C=10.0, gamma='scale', random_state=42)\n",
    "    svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = svm_model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    print(f\"ê°œì„ ëœ ëª¨ë¸ ì •í™•ë„: {accuracy:.2%}\")\n",
    "    print(\"\\n[ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸]\")\n",
    "    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "    print(report)\n",
    "    \n",
    "    mlflow.sklearn.log_model(svm_model, \"captcha_model\")\n",
    "    \n",
    "    joblib.dump(svm_model, \"../models/captcha_svm_model.pkl\")\n",
    "    joblib.dump(label_encoder, \"../models/label_encoder.pkl\")\n",
    "    joblib.dump(scaler, \"../models/scaler.pkl\")\n",
    "    print(\"ëª¨ë¸, ë ˆì´ë¸” ì €ì¥ ì™„ë£Œ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
