{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Captcha Recognition with CNN (TensorFlow/Keras)\n",
                "\n",
                "This notebook implements a Convolutional Neural Network (CNN) to recognize captcha characters. \n",
                "It replaces the traditional SVM + HOG approach with a deep learning model for potentially higher accuracy.\n",
                "\n",
                "## Pipeline\n",
                "1. **Load Data**: Download dataset from Kaggle.\n",
                "2. **Preprocessing**: Segmentation mechanism (Same as current project).\n",
                "3. **Data Preparation**: Convert segmented characters to 32x32 arrays for CNN input.\n",
                "4. **Model**: Build and train a CNN.\n",
                "5. **Evaluation**: Check accuracy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "!pip install -q scikit-image scikit-learn pandas joblib kagglehub matplotlib seaborn tqdm tensorflow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Imports\n",
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "from tqdm.notebook import tqdm\n",
                "from skimage.io import imread\n",
                "from skimage.color import rgb2gray\n",
                "from skimage.filters import threshold_otsu\n",
                "from skimage.transform import resize\n",
                "from skimage.morphology import opening, footprint_rectangle, remove_small_objects\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "import kagglehub\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models, callbacks\n",
                "\n",
                "print(f\"TensorFlow Version: {tf.__version__}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Preprocessing Logic (Consistent with Project)\n",
                "\n",
                "def preprocess_image_v3(img):\n",
                "    # Handle different channel configurations reliably\n",
                "    if img.ndim == 3:\n",
                "        if img.shape[2] == 4:\n",
                "            img = img[..., :3]\n",
                "        img_gray = rgb2gray(img)\n",
                "    else:\n",
                "        # Already grayscale 2D array\n",
                "        img_gray = img\n",
                "        \n",
                "    img_resized = resize(img_gray, (50, 200))\n",
                "    \n",
                "    # Global Otsu\n",
                "    thresh = threshold_otsu(img_resized)\n",
                "    img_bin = img_resized > thresh\n",
                "    \n",
                "    # Background Check\n",
                "    corners = [img_bin[0,0], img_bin[0,-1], img_bin[-1,0], img_bin[-1,-1]]\n",
                "    if np.mean(corners) < 0.5: \n",
                "        img_inv = img_bin.astype(np.uint8)\n",
                "    else:\n",
                "        img_inv = (1 - img_bin).astype(np.uint8)\n",
                "    \n",
                "    # Clean up\n",
                "    img_cleaned = opening(img_inv, footprint_rectangle((2, 2)))\n",
                "    img_cleaned = remove_small_objects(img_cleaned.astype(bool), min_size=20).astype(np.uint8)\n",
                "    \n",
                "    return img_cleaned\n",
                "\n",
                "def segment_characters_v2(img_cleaned, num_chars=5):\n",
                "    projection = np.sum(img_cleaned, axis=0)\n",
                "    threshold = np.max(projection) * 0.1\n",
                "    is_char = projection > threshold\n",
                "    \n",
                "    char_indices = []\n",
                "    in_char = False\n",
                "    start = 0\n",
                "    for i, val in enumerate(is_char):\n",
                "        if val and not in_char:\n",
                "            start = i\n",
                "            in_char = True\n",
                "        elif not val and in_char:\n",
                "            width = i - start\n",
                "            if width >= 2:\n",
                "                if width > 50:\n",
                "                    num_splits = round(width / 32)\n",
                "                    split_w = width / num_splits\n",
                "                    for s in range(num_splits):\n",
                "                        char_indices.append((int(start + s*split_w), int(start + (s+1)*split_w)))\n",
                "                else:\n",
                "                    char_indices.append((start, i))\n",
                "            in_char = False\n",
                "    if in_char:\n",
                "        char_indices.append((start, len(is_char)))\n",
                "\n",
                "    characters = []\n",
                "    for (start, end) in char_indices[:num_chars]:\n",
                "        char_img = img_cleaned[:, start:end]\n",
                "        h, w = char_img.shape\n",
                "        if h == 0 or w == 0: continue\n",
                "        \n",
                "        diff = abs(h - w)\n",
                "        p1, p2 = diff // 2, diff - (diff // 2)\n",
                "        if h > w:\n",
                "            char_img = np.pad(char_img, ((0, 0), (p1, p2)), mode='constant')\n",
                "        else:\n",
                "            char_img = np.pad(char_img, ((p1, p2), (0, 0)), mode='constant')\n",
                "            \n",
                "        char_img_resized = resize(char_img, (32, 32))\n",
                "        characters.append(char_img_resized)\n",
                "    \n",
                "    while len(characters) < num_chars:\n",
                "        characters.append(np.zeros((32, 32)))\n",
                "        \n",
                "    return characters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Prepare Data\n",
                "\n",
                "print(\"Downloading dataset...\")\n",
                "path = kagglehub.dataset_download(\"fournierp/captcha-version-2-images\")\n",
                "images_dir = Path(path) / \"samples\"\n",
                "image_files = list(images_dir.glob(\"*.png\")) + list(images_dir.glob(\"*.jpg\"))\n",
                "\n",
                "X = []\n",
                "y = []\n",
                "\n",
                "print(\"Processing images...\")\n",
                "for path in tqdm(image_files, desc=\"Segmenting\"):\n",
                "    try:\n",
                "        img = imread(str(path))\n",
                "        label_text = path.stem\n",
                "        \n",
                "        img_cleaned = preprocess_image_v3(img)\n",
                "        char_images = segment_characters_v2(img_cleaned, num_chars=5)\n",
                "        \n",
                "        if len(char_images) == len(label_text):\n",
                "            for char_img, char_label in zip(char_images, label_text):\n",
                "                # CNN Input: Need 32x32x1 shape\n",
                "                X.append(char_img)\n",
                "                y.append(char_label)\n",
                "    except Exception as e:\n",
                "        continue\n",
                "\n",
                "X = np.array(X)\n",
                "X = X.reshape(-1, 32, 32, 1) # Add channel dimension\n",
                "y = np.array(y)\n",
                "\n",
                "le = LabelEncoder()\n",
                "y_enc = le.fit_transform(y)\n",
                "\n",
                "print(f\"Original X Shape: {X.shape}\")\n",
                "print(f\"Classes: {le.classes_}\")\n",
                "print(f\"Num Classes: {len(le.classes_)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Build CNN Model\n",
                "\n",
                "num_classes = len(le.classes_)\n",
                "\n",
                "def create_cnn_model():\n",
                "    model = models.Sequential([\n",
                "        # Conv Block 1\n",
                "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
                "        layers.MaxPooling2D((2, 2)),\n",
                "        \n",
                "        # Conv Block 2\n",
                "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
                "        layers.MaxPooling2D((2, 2)),\n",
                "        \n",
                "        # Conv Block 3\n",
                "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
                "        # layers.MaxPooling2D((2, 2)), # Optional depending on size\n",
                "        \n",
                "        layers.Flatten(),\n",
                "        layers.Dense(64, activation='relu'),\n",
                "        layers.Dropout(0.2), # Reduce Overfitting\n",
                "        layers.Dense(num_classes, activation='softmax')\n",
                "    ])\n",
                "    \n",
                "    model.compile(optimizer='adam',\n",
                "                  loss='sparse_categorical_crossentropy',\n",
                "                  metrics=['accuracy'])\n",
                "    return model\n",
                "\n",
                "model = create_cnn_model()\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Train Model\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=42, stratify=y_enc)\n",
                "\n",
                "early_stopping = callbacks.EarlyStopping(\n",
                "    monitor='val_loss',\n",
                "    patience=5,\n",
                "    restore_best_weights=True\n",
                ")\n",
                "\n",
                "history = model.fit(\n",
                "    X_train, y_train,\n",
                "    epochs=30,\n",
                "    batch_size=32,\n",
                "    validation_data=(X_test, y_test),\n",
                "    callbacks=[early_stopping]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Evaluation\n",
                "\n",
                "plt.figure(figsize=(12, 4))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(history.history['accuracy'], label='Train Acc')\n",
                "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
                "plt.legend()\n",
                "plt.title('Accuracy')\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(history.history['loss'], label='Train Loss')\n",
                "plt.plot(history.history['val_loss'], label='Val Loss')\n",
                "plt.legend()\n",
                "plt.title('Loss')\n",
                "plt.show()\n",
                "\n",
                "# Detailed Report\n",
                "y_pred_probs = model.predict(X_test)\n",
                "y_pred = np.argmax(y_pred_probs, axis=1)\n",
                "\n",
                "print(classification_report(le.inverse_transform(y_test), le.inverse_transform(y_pred)))\n",
                "\n",
                "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
                "print(f\"\\nTest Accuracy: {test_acc*100:.2f}%\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}